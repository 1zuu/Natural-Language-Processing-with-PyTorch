{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a597b4-3260-4430-b985-efad9178d8db",
   "metadata": {},
   "source": [
    "# **Import Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5a55e12-1f74-4ba5-8c25-afdefe93d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b5a102-8703-47a1-9b38-186c9da45bef",
   "metadata": {},
   "source": [
    "# **Data Paths /  Weights / Hparams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61d136ec-7a9e-4a9c-af44-f0732833082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'tweets.csv'\n",
    "headers = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "random_state = 1234\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "\n",
    "oov_token = '<OOV>'\n",
    "pad_token = '<PAD>'\n",
    "device = 'cpu'\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb48343-aef6-48a9-a6af-2395c6d0f8dd",
   "metadata": {},
   "source": [
    "# **Load Intital Data Set, Analyze, Preprocess & VIsualize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f3b00c-2c13-46ba-845b-8ba62909f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_namet, down_sample=True):\n",
    "    data = pd.read_csv(\n",
    "                    file_name,\n",
    "                    names=headers,\n",
    "                    encoding='latin-1'\n",
    "                    )\n",
    "    \n",
    "    data = shuffle(data)\n",
    "    \n",
    "    data = data[['target', 'text']]\n",
    "    data['target'] = data['target'].astype(int)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    if down_sample:\n",
    "        data = data.sample(\n",
    "                        frac=0.01, \n",
    "                        replace=False, \n",
    "                        random_state=random_state\n",
    "                        ) # Since I have Limited Resources I downsample the dataset heavily\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "badcd5c0-0983-4165-9f57-a53ade8110ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_class_imbalance(data):\n",
    "    target = data['target'].values\n",
    "    counts = pd.Series(target).value_counts()\n",
    "    sns.barplot(\n",
    "            x=np.array(['negative','positive']),\n",
    "            y=counts.values\n",
    "               )  \n",
    "    plt.title('Class Imbalance of Twitter Dataset')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.xlabel('Counts')\n",
    "    plt.savefig('imbalance.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc1049a-fd12-4131-bf2e-ea54761ea35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(lemmatizer,sentence):\n",
    "    lem = [lemmatizer.lemmatize(k) for k in sentence]\n",
    "    return [k for k in lem if k]\n",
    "\n",
    "def remove_stop_words(stopwords_list,sentence):\n",
    "    return [k for k in sentence if k not in stopwords_list]\n",
    "\n",
    "def preprocess_one(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    remove_punc = tokenizer.tokenize(tweet) # Remove puntuations\n",
    "    remove_num = [re.sub('[0-9]', '', i) for i in remove_punc] # Remove Numbers\n",
    "    remove_num = [i for i in remove_num if len(i)>0] # Remove empty strings\n",
    "    lemmatized = lemmatization(lemmatizer,remove_num) # Word Lemmatization\n",
    "    remove_stop = remove_stop_words(stopwords_list,lemmatized) # remove stop words\n",
    "    updated_tweet = ' '.join(remove_stop)\n",
    "    return updated_tweet\n",
    "\n",
    "def preprocessed_data(tweets):\n",
    "    updated_tweets = []\n",
    "    if isinstance(tweets, np.ndarray) or isinstance(tweets, list):\n",
    "        for tweet in tweets:\n",
    "            updated_tweet = preprocess_one(tweet)\n",
    "            updated_tweets.append(updated_tweet)\n",
    "    elif isinstance(tweets, np.str_)  or isinstance(tweets, str):\n",
    "        updated_tweets = [preprocess_one(tweets)]\n",
    "\n",
    "    return np.array(updated_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aede67f6-f3c3-4ab8-b7ed-8f99cd389d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21afd7d9-3fad-4fc1-b640-40c57f0523c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_class_imbalance(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f9753a-7839-4b30-9315-b3e3efcf7b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples : 11560\n",
      "Val   Samples : 2040\n",
      "Test  Samples : 2400\n"
     ]
    }
   ],
   "source": [
    "tweets = data['text'].values\n",
    "targets = data['target'].values\n",
    "\n",
    "tweets, targets = shuffle(tweets, targets)\n",
    "\n",
    "tweets = preprocessed_data(tweets)\n",
    "\n",
    "X, X_test, Y, Y_test = train_test_split(\n",
    "                                    tweets, \n",
    "                                    targets, \n",
    "                                    test_size=test_size, \n",
    "                                    random_state=random_state\n",
    "                                    )\n",
    "\n",
    "X, X_val, Y, Y_val = train_test_split(\n",
    "                                    X, \n",
    "                                    Y, \n",
    "                                    test_size=val_size, \n",
    "                                    random_state=random_state\n",
    "                                    )\n",
    "\n",
    "print('Train Samples : {}'.format(len(Y)))\n",
    "print('Val   Samples : {}'.format(len(Y_val)))\n",
    "print('Test  Samples : {}'.format(len(Y_test)))\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "\n",
    "Y = encoder.transform(Y)\n",
    "Y_val = encoder.transform(Y_val)\n",
    "Y_test = encoder.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3fa0b1-e98f-42ee-af16-1370fa4e3a0d",
   "metadata": {},
   "source": [
    "# **Create Vocabulary, Tokenization & Padding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52adde03-84d5-4664-b8dc-d55eb4c320d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vocabulary(X):\n",
    "    vocab = {}\n",
    "    for x in X:\n",
    "        tokens = x.split(' ')\n",
    "        for token in tokens:\n",
    "            if token in vocab:\n",
    "                vocab[token] += 1\n",
    "            else:\n",
    "                vocab[token] = 1\n",
    "                \n",
    "    vocab  = dict(\n",
    "                sorted(\n",
    "                    vocab.items(), \n",
    "                    key=lambda item: item[1], \n",
    "                    reverse=True\n",
    "                       )\n",
    "                )\n",
    "    vocab = {token : idx+1 for idx, token in enumerate(list(vocab.keys()))}\n",
    "    \n",
    "    vocab[oov_token] = len(vocab) + 1\n",
    "    vocab[pad_token] = 0\n",
    "    \n",
    "    print(f'The Size of the Vocabulary is {len(vocab)}')\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "def tokenize_data(tweets, vocab):\n",
    "    sequences = []\n",
    "    for tweet in tweets:\n",
    "        tokens = tweet.split(' ')\n",
    "        sequence = [vocab[token] if (token in vocab) else vocab[oov_token] for token in tokens]\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "def vis_length_variation(X_SEQ):\n",
    "    X_len = [len(i) for i in X_SEQ]\n",
    "    X_len = pd.Series(X_len)\n",
    "    X_len.hist()\n",
    "    plt.xlabel('Token Length')\n",
    "    plt.ylabel('Samples')\n",
    "    plt.savefig('sequence length.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print(X_len.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5861cdac-a508-4f9c-856e-95243cdd11ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Size of the Vocabulary is 18879\n"
     ]
    }
   ],
   "source": [
    "vocab = extract_vocabulary(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ef2ec47-b910-43ec-a3f9-ccc3fe9ffe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_SEQ = tokenize_data(X, vocab)\n",
    "X_val_SEQ = tokenize_data(X_val, vocab)\n",
    "X_test_SEQ = tokenize_data(X_test, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "266b930e-6635-4529-8bf2-72bc60eaf689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    11560.000000\n",
      "mean         7.768426\n",
      "std          4.088910\n",
      "min          1.000000\n",
      "25%          5.000000\n",
      "50%          7.000000\n",
      "75%         11.000000\n",
      "max         78.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "vis_length_variation(X_SEQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31912f97-a364-493a-80e9-a9c5accebb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7928cd45-3961-4907-ad9d-f030906e775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tokens(sequences, max_length=max_length):\n",
    "    seq_tensor = np.zeros((len(sequences), max_length))\n",
    "    for idx, sequence in enumerate(sequences):\n",
    "        if len(sequence) >= max_length:\n",
    "            seq_tensor[idx, :] = np.array(sequence[:max_length])\n",
    "        else:\n",
    "            redundancy_length = max_length - len(sequence)\n",
    "            padded_sequence = [vocab[pad_token]] * redundancy_length + sequence\n",
    "            seq_tensor[idx, :] = np.array(padded_sequence)\n",
    "            \n",
    "    return seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec89c16a-f8e6-4b9b-a6f3-1944fe49ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PAD = pad_tokens(X_SEQ)\n",
    "X_val_PAD = pad_tokens(X_val_SEQ)\n",
    "X_test_PAD = pad_tokens(X_test_SEQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "327c1488-bdc1-4201-9cac-e40eefa0deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PAD = X_PAD.astype(np.int32)\n",
    "X_val_PAD = X_val_PAD.astype(np.int32)\n",
    "X_test_PAD = X_test_PAD.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0babf45-00e0-470c-a395-193d63079be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   256,     3,    48],\n",
       "       [    0,     0,     0, ...,     0,    36,   477],\n",
       "       [    0,     0,     0, ...,    40,    73,     2],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  5277,    18, 18875],\n",
       "       [    0,     0,     0, ...,  1070,    85,    18],\n",
       "       [    0,     0,     0, ...,     0, 18877,  2549]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_PAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5161a2fd-0fae-485e-a70e-f16e2b8b10ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   299,   129,   124],\n",
       "       [    0,     0,     0, ...,    86,   106,   991],\n",
       "       [    0,     0,     0, ...,     0, 18878,  1112],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  6448,     3,    40],\n",
       "       [    0,     0,     0, ...,     6,   852,   410],\n",
       "       [    0,     0,     0, ...,  1810,    83,  2993]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_PAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c43cd898-9711-430a-88ee-f0098e38908e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    44,    25,   466],\n",
       "       [    0,     0,     0, ...,    99,    15, 18878],\n",
       "       [    0,     0,     0, ...,    25, 18878,    33],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  5225, 18878,  2965],\n",
       "       [    0,     0,     0, ...,     2,   852,    43],\n",
       "       [    0,     0,     0, ...,  1335, 18878,     2]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_PAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df078f91-0c41-44d7-9b61-ff0da7f92282",
   "metadata": {},
   "source": [
    "# **Numpy to Troch DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "925b8c5a-b821-432b-9a99-1718d952da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor Dataset\n",
    "train_data = TensorDataset(\n",
    "                    torch.from_numpy(X_PAD), \n",
    "                    torch.from_numpy(Y)\n",
    "                            )\n",
    "\n",
    "valid_data = TensorDataset(\n",
    "                    torch.from_numpy(X_val_PAD), \n",
    "                    torch.from_numpy(Y_val)\n",
    "                            )\n",
    "\n",
    "test_data = TensorDataset(\n",
    "                    torch.from_numpy(X_test_PAD), \n",
    "                    torch.from_numpy(Y_test)\n",
    "                            )\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(\n",
    "                    train_data, \n",
    "                    shuffle=True, \n",
    "                    drop_last=True,\n",
    "                    batch_size=batch_size\n",
    "                        )\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "                    valid_data, \n",
    "                    shuffle=True, \n",
    "                    drop_last=True,\n",
    "                    batch_size=batch_size\n",
    "                        )\n",
    "\n",
    "test_data = DataLoader(\n",
    "                    test_data, \n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    batch_size=batch_size\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "872351f6-7e1e-4c61-bb87-031ef5dd9cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input  Sample : \n",
      "tensor([[    0,     0,     0,  ...,    36,  3212,    42],\n",
      "        [    0,     0,     0,  ...,   580,     4, 11734],\n",
      "        [    0,     0,     0,  ...,  5277,    18, 18875],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,    37,     3,   649],\n",
      "        [    0,     0,     0,  ...,   574, 16334,   362],\n",
      "        [    0,     0,     0,  ...,   193,   366,   106]], dtype=torch.int32)\n",
      "Output Sample : \n",
      "tensor([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# Check the Data Shapes of DataLoader Iteration\n",
    "x_next, y_next = iter(train_loader).next()\n",
    "\n",
    "print('Input  Sample : \\n{}'.format(x_next.to(device)))\n",
    "print('Output Sample : \\n{}'.format(y_next.to(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e2fdb-69b5-402e-b841-9259ff8f19fc",
   "metadata": {},
   "source": [
    "# **Sentiment Analysis LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc7b78a3-f778-4187-ad42-a45021baee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis(nn.Module):\n",
    "    def __init__(\n",
    "                self, \n",
    "                vocab_size, \n",
    "                num_layers=2,\n",
    "                embedding_dim=256,\n",
    "                hidden_dim_lstm=256,\n",
    "                hidden_dim_linear1=512,\n",
    "                hidden_dim_linear2=256,\n",
    "                hidden_dim_linear3=64,\n",
    "                dropout_rate = 0.4,\n",
    "                device=device\n",
    "                ):\n",
    "        super(SentimentAnalysis,self).__init__()\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "                                input_size=embedding_dim,\n",
    "                                hidden_size=hidden_dim_lstm,\n",
    "                                num_layers=num_layers, \n",
    "                                batch_first=True\n",
    "                                )\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.linear_layer0 = nn.Linear(hidden_dim_lstm, hidden_dim_linear1)\n",
    "        self.linear_layer1 = nn.Linear(hidden_dim_linear1, hidden_dim_linear2)\n",
    "        self.linear_layer2 = nn.Linear(hidden_dim_linear2, hidden_dim_linear3)\n",
    "        self.linear_layer3 = nn.Linear(hidden_dim_linear3, 1)\n",
    "        \n",
    "        self.output_layer = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "        self.device = device\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim_lstm = hidden_dim_lstm\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        h_init = torch.zeros(self.num_layers, batch_size, self.hidden_dim_lstm).to(self.device)\n",
    "        c_init = torch.zeros(self.num_layers, batch_size, self.hidden_dim_lstm).to(self.device)\n",
    "        \n",
    "        memory_init = (h_init, c_init)\n",
    "        \n",
    "        x = self.embedding_layer(x)\n",
    "        x, _ = self.lstm_layer(x, memory_init) \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        output shape : (batch_size, sequence_length, hidden_dim)\n",
    "        \n",
    "        But we only need the output of last time step (end of the sequence). so the \n",
    "        required output shape is,\n",
    "                       (batch_size, 1, hidden_dim)\n",
    "                       \n",
    "        After Squeezing over 2nd dimension output should be,\n",
    "                       (batch_size, hidden_dim) \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        x = x[:,-1,:]\n",
    "        x = x.view(batch_size, self.hidden_dim_lstm)\n",
    "        \n",
    "        x = self.dropout_layer(x)\n",
    "        x = self.linear_layer0(x)\n",
    "        x = self.linear_layer1(x)\n",
    "        x = self.linear_layer2(x)\n",
    "        x = self.linear_layer3(x)\n",
    "        \n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a776220-4d7d-4568-b692-602286d616d5",
   "metadata": {},
   "source": [
    "# **Model Loss / Optimizer & Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "419c790b-ffe4-43c2-945d-c8ac9131eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) + 1\n",
    "model = SentimentAnalysis(vocab_size)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ecd74ec3-ab90-4e1c-81c0-c1dc645efc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "                        model.parameters(), \n",
    "                        lr = learning_rate\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3cd3e78a-dda6-4a15-8b57-540b3eb0ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabefea3-00a0-4807-8a76-568b39f91153",
   "metadata": {},
   "source": [
    "# **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fccdec52-82b0-46f8-a108-30d07fc870d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    \n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    \n",
    "    val_epoch_loss = 0\n",
    "    val_epoch_acc = 0\n",
    "\n",
    "    model.train() # Training the Model\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs).squeeze(1)\n",
    "        loss = criterion(predictions, labels.float())\n",
    "        acc = binary_accuracy(predictions, labels.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += loss.item()\n",
    "        train_epoch_acc += acc.item()\n",
    "        \n",
    "    train_epoch_loss = train_epoch_loss / len(train_loader)\n",
    "    train_epoch_acc = train_epoch_acc / len(train_loader)\n",
    "    \n",
    "    model.eval() # Validate the Model\n",
    "        \n",
    "    for inputs, labels in tqdm(valid_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device) \n",
    "        \n",
    "        predictions = model(inputs).squeeze()\n",
    "\n",
    "        loss = criterion(predictions, labels.float())\n",
    "        acc = binary_accuracy(predictions, labels.float())\n",
    "        \n",
    "        val_epoch_loss += loss.item()\n",
    "        val_epoch_acc += acc.item()\n",
    "        \n",
    "    val_epoch_loss = val_epoch_loss / len(valid_loader)\n",
    "    val_epoch_acc = val_epoch_acc / len(valid_loader)\n",
    "    \n",
    "    return train_epoch_loss, train_epoch_acc, val_epoch_loss, val_epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4990b-d4fe-4b5d-b0af-496508a62cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 180/180 [09:00<00:00,  3.00s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:16<00:00,  1.89it/s]\n",
      "  0%|                                                                                          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.674, Validation Loss : 0.622\n",
      "Train Acc  : 0.565, Validation Acc  : 0.648\n",
      "Epoch 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 180/180 [36:51<00:00, 12.29s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [02:54<00:00,  5.63s/it]\n",
      "  0%|                                                                                          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.596, Validation Loss : 0.591\n",
      "Train Acc  : 0.676, Validation Acc  : 0.671\n",
      "Epoch 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 180/180 [22:39<00:00,  7.55s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:19<00:00,  1.57it/s]\n",
      "  0%|                                                                                          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.546, Validation Loss : 0.573\n",
      "Train Acc  : 0.719, Validation Acc  : 0.702\n",
      "Epoch 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████                                     | 98/180 [04:59<03:11,  2.34s/it]"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    print('Epoch {}\\n'.format(epoch))\n",
    "    train_epoch_loss, train_epoch_acc, val_epoch_loss, val_epoch_acc = train_epoch()\n",
    "    \n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_acc.append(train_epoch_acc)\n",
    "    \n",
    "    val_loss.append(val_epoch_loss)\n",
    "    val_acc.append(val_epoch_acc)\n",
    "    \n",
    "    print('Train Loss : {}, Validation Loss : {}'.format(\n",
    "                                                    round(train_epoch_loss, 3), \n",
    "                                                    round(val_epoch_loss, 3)\n",
    "                                                         ))\n",
    "    print('Train Acc  : {}, Validation Acc  : {}'.format(\n",
    "                                                    round(train_epoch_acc, 3),  \n",
    "                                                    round(val_epoch_acc, 3)\n",
    "                                                        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a833e17-3feb-40d6-a6b6-a02db9ad0d5b",
   "metadata": {},
   "source": [
    "# **Visualize the Performance Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9757522-3eb6-4936-8c4b-e3b8b5f0d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label='Train Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Train loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.title('Performance Metrics of Sentiment Analysis Model')\n",
    "plt.savefig('performance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9ff28-551d-4cfd-89fb-a40262d99b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
